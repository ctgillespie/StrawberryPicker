# Strawberry Picker/Mover
## Introduction
The impetus behind this project was to develop a small prototype for a strawberry moving robot for use in vertical farming applications. Vertical farms typically have plants growing out of a cylinder to save on space. However, the spacing between plants in the cylinder is important to ensure that each plant has the room it needs to grow. Moving these plants is a task that can easily be automated with the use of a pick-and-place machine designed to operate on the cylinder. <br /> <br />
This project serves as a proof-of-concept for such a system. It uses a foam roller with push-pins as a representative model of the vertical farm and strawberries. The roller is rotated by a stepper motor and the pins are manipulated using a robotic arm with a gripper mounted to it. The arm uses one stepper motor for its base, a modified servo for its elbow, and an un-modified servo for its wrist and claw.
## Hardware Design
The prototype system consists of two parts: and arm and a rotating roller “canvas”. The roller is fairly simplistic and is just a foam exercise roller mounted on top of on of the stepper motors. The roller is very lightweight so the motor can easily spin it. The only transverse force it will need to support is the force of having a pin pushed into it, but since the pins go in easily, the force is not unsupportable. The arm design is a little bit more complicated. Parts of the robot arm were 3D printed from [this 3D model](https://thangs.com/designer/m/3d-model/38899) found on thangs.com. Namely, the forearm and the claw were printed based on that design. Mini servo motors were used to actuate the grabber and to rotate it up and down. The design on thangs.com also includes a servo to rotate the grabber, but that servo was removed for this project since the grabber does not need to rotate to pick and place pins. The wrist is actuated by a larger servo motor as it needs to provide more torque. In the spirit of rapid prototyping, the rest of the structure including the upper arm and the base were made of wood. The second stepper motor serves as the base motor for the whole arm. A picture of the system (without electronics for clarity) is shown below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/Prototype.jpg?raw=true "Prototype System")
Future work on the hardware design would include designing a gearbox for the base stepper motor as it struggles to provide enough torque to move the arm in certain positions. Additionally, once a final design is settled upon, the remaining wood parts can be recreated using a lighter yet strong material that fits the form better.
## Motor Driver
The first step in getting the motor driver to operate correctly was to solder the connectors to the custom breakout board for the TMC4210s and the TMC2208s along with adding a capacitor and heat-sinks. Once the board was prepared, it was connected to the Nucleo board and the two stepper motors as shown below. 
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/MotorWiringDiagram.png?raw=true "Wiring Diagram")<br /><br />
In order to get the motors to run properly, there are several set-up steps that must be followed to configure the TMC4210 properly. Firstly, the enable pin *en_sd* must be set to 1 to enable interfacing with the motor driver. Next, the *V_MIN* and *V_MAX* parameters are set to 2 and 8 respectively. These parameters are used to tell the motor below which speed it can stop and to put an upper bound on the velocity of the motor respectively. Next, *PULSE_DIV* and *RAMP_DIV* are used to set the clock pre-dividers. An image of the clock signal on the oscilloscope operating at 20 MHz is shown below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/ClockSignal.png?raw=true "Clock Signal")<br /><br />
Next, *A_MAX* must be set. *A_MAX* defines the acceleration/deceleration ramp used for moving to a target. It is important to set it accurately otherwise the motor may stop short or overshoot. In this case, it is set to 2. In order to set it correctly, *P_MUL* and *P_DIV* are set using the equation below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/PMUL.PNG?raw=true "PMUL Equation")<br /><br />
This equation gives PMUL as a function of PDIV, so the motor driver set up code will try all 14 possibilities of PDIV to find the associated PMUL that works with it. Next, *RAMP_MODE* is set to 0 or X_TARGET mode. mot1r was set to 1 for a left and right reference switch. After that, the motor driver is ready to receive commands. In order to move the motor, a position is written to the *X_TARGET* register. <br /> <br />
After the clock signal was verified, the next step was to verify that the data was being sent correctly. The scope captures below show both MOSI and MISO lines. Note that the yellow signal is nCS1, green is SCK, and blue is CLK. The data is shown at the bottom using the serial decoding feature.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/DataCaptures.PNG?raw=true "Data Scope Capture")<br /><br />
The data is also verified by printing it to the console. This is also shown in the image below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/DataInConsole.PNG?raw=true "Data In Console")<br /><br />
Lastly, a motor driver class was written to make the code more modular and object-oriented so that it can be made to integrate easily with other projects. A diagram of the class is shown.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/MotorDriverClassDiagram.png?raw=true "Motor Driver Class Diagram") <br />
[A video of the motors spinning can be found here](https://drive.google.com/file/d/1Qb-K9VdT-8qYitZVEhLl1PaHGWKx7_Ab/view?usp=sharing)
## Image Parsing
The functionality of the robot was expanded beyond the simple pick-and-place system described in the introduction into something that can “draw” pictures by placing the pins in certain places on the roller. In order to load these images onto the controller, the pictures are first drawn in *Inkscape*. In order to draw a picture in a way that the program can recognize, the circle tool is used. A red circle (or any color other than black) indicates a starting location for a pin and a black circle indicates a final location. The circles may be created using any size. An example image is shown below. <br />
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/SmileDrawing.PNG?raw=true "Smile Example")
Because each circle represents an initial or final pin position, the number of red (start) positions must equal the number of black (end) positions. Once the drawing is complete, it is exported as an xml file so that the locations of each start and end positions can be read in. The corresponding xml file for the example image above is included in the files attached with this report above.
## Motor Command Generation
The xml file is then read into the Jupyter file [GenerateMotorCommands.py](https://github.com/ctgillespie/StrawberryPicker/blob/main/GenerateMotorCommands.ipynb) which, as the name suggests, generates motor commands based on the xml of the image provided. Firstly, it parses through the xml file and creates StartPoint and EndPoint objects for each pin, including the position and placed state. Each object is added to a list that the code will use to build a path from. The buildPath function will pop a start location off of the list, then use a custom interpolation function to make intermediate X, Y, and Z points for the robot to follow. This interpolation function can be tuned to either speed up or slow down the operation of the robot. Next, the buildPath function will call the pick function which will add in the X, Y, and Z coordinates to open the grabber, move in horizontally, close the grabber, and move out horizontally. Then another genPath function is called to move from the pick location to the place location. The place function is then called to do the opposite of the pick function. This whole process repeats, adding X, Y, Z locations and a Grab flag to an ever growing array to describe the entire motion of the robot as it draws the image. Finally, once the buildPath function is done, a Newton-Raphson solver is applied to each time step to convert X, Y, Z into motor locations to each of the four motors, under the constraint that the grabber must always remain horizontal. These motor commands along with the grab flag (1 for closed, 0 for open) are plotted below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/MotorCommandGraph.PNG?raw=true "Motor Commands")
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/GrabGraph.PNG?raw=true "Grab Commands")
Using the motor data over time, an animation can be created to show the operation of the arm as it goes through the motions of picking and placing the pins as per the smile example given above. This animation is shown below. Note that the animation does not show either the roller rotating or the grabber actuating. However, the actuation of these parts is more trivial as it is just a proportional relationship between rotated angle and distance for the former and just a binary open/close for the latter.<br />
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/armgif.gif?raw=true "Arm Animation")
## Cooperative Multitasking
At the highest level, the code onboard the Nucleo board runs cooperatively. After the initial set-up of writing the parameters to the motor board (as described in the Motor Driver section above), the multi-tasking part of the operation begins. There are two main tasks that run simultaneously. One reads the motor commands and the other writes to the motors. Since the Nucleo board has limited RAM, the motor commands are loaded in as a CSV which can be saved on the device memory. The read commands task reads a chunk of the file at a time and shares it with the write commands task. This way, the system will not get a memory error for larger drawings. The task diagram for this operation is shown below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/TaskDiagram.PNG?raw=true "Task Diagram")
The read task starts by opening the csv file with all the motor commands. It then will enter the parse motor commands state where it will parse one command at a time and add it to various shares for the write task to make use of until it reaches the end of the file. This functionality is shown in the state transition diagram below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/ReadCommandsSTD.PNG?raw=true "Read Commands State Transition Diagram")
The write task is even simpler as all it does is read from the shares to get the current motor positions and write that to the motors using the motor driver class. The simple diagram is shown below.
![alt text](https://github.com/ctgillespie/StrawberryPicker/blob/main/Photos/WriteCommandsSTD.PNG?raw=true "Write Commands State Transition Diagram")
## Demonstration
